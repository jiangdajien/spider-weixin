# 如何解析爬虫爬取回来的数据
* 1、HTML基础知识回顾
* 2、使用Document获取文本数据
* 3、使用Jsoup操作HTML文档
	* 3.1、Jsoup 是什么？
	* 3.2、JSOUP的核心功能
	* 3.3、如何使用Jsoup选择器获取数据
	* 3.4、Jsoup的maven依赖
	* 3.5、HTML页面解析实战

# 1、HTML基础知识回顾
HTML知识回顾
* 什么是 HTML？
	* HTML 指的是超文本标记语言 (Hyper Text Markup Language)，“超文本”就是指页面内可以包含图片、链接，甚至音乐、程序等非文字元素。
	* 超文本标记语言的结构包括“头”部分（英语：Head）、和“主体”部分（英语：Body），其中“头”部提供关于网页的信息，“主体”部分提供网页的具体内容。
* HTML的构成
	head 元素是所有头部元素的容器。<head> 内的元素可包含脚本，指示浏览器在何处可以找到样式表，提供元信息，等等。
以下标签都可以添加到 head 部分。[更多信息](http://www.w3school.com.cn/html/html_head.asp)
	* HTML
		* head
			* title 
				* 定义浏览器工具栏中的标题
				* 提供页面被添加到收藏夹时显示的标题
				* 显示在搜索引擎结果中的页面标题
			* base
				* 标签为页面上的所有链接规定默认地址或默认目标（target）
					```java <base href="http://www.w3school.com.cn/images/" /> ``
					```java <base target="_blank" /> ```
			* link
				* 定义文档与外部资源之间的关系
				* 标签最常用于连接样式表
				* ```java <link rel="stylesheet" type="text/css" href="mystyle.css" />```
			* meta
				* 元数据（metadata）是关于数据的信息
				* 元数据总是以名称/值的形式被成对传递的
				* 标签提供关于 HTML 文档的元数据。元数据不会显示在页面上，但是对于机器是可读的。
				* 典型的情况是，meta 元素被用于规定页面的描述、关键词、文档的作者、最后修改时间以及其他元数据。
					* http-equiv 服务器发送给服务器的标识
						* content-type 文档类型，[查看更多的content-type相关](http://tool.oschina.net/commons/)
								所有服务器都**至少**要发送一个：content-type:text/html。这将告诉浏览器准备接受一个 HTML 文档。
						* expires 文档过期时间
							```java <meta http-equiv="expires" content="31 Dec 2008"> ```
						* refresh 用于刷新与跳转(重定向)页面
							* 5秒之后刷新本页面
								```java <meta http-equiv="refresh" content="5" />```
							* 5秒之后转到[传智播客](http://www.itcast.cn)首页
								```java <meta http-equiv="refresh" content="5; url=http://www.itcast.cn/" />```
						* set-cookie cookie设定，如果网页过期，存盘的cookie将被删除。需要注意的也是必须使用GMT时间格式； 
							```java <meta    http-equiv="set-cookie"    contect="Mon,12    May    2001    00:20:00    GMT(格林尼治标准时间)"> ```    
						* charset 文档编码格式
							```java <meta http-equiv="charset" content="iso-8859-1">```
					* name
						* author 告诉搜索引擎你的站点的制作的作者
						* description 告诉搜索引擎你的站点的主要内容
						* keywords 向搜索引擎说明你的网页的关键词
						* generator  用以说明生成工具
						* revised 定义页面的最新版本
						* others 其它
					* scheme 
						* some_text
		
					* **一些搜索引擎会利用 meta 元素的 name 和 content 属性来索引您的页面。**
			* script
					* 标签用于定义客户端脚本，比如 JavaScript。
			* style
				* 标签用于为 HTML 文档定义样式信息
				 ```java <style type="text/css"> body {background-color:yellow} p {color:blue} </style>```
		* body
	* HTML

# 2、使用Document获取文本数据
* Document是什么
每个载入浏览器的 HTML 文档都会成为 Document 对象。
Document 对象使我们可以从脚本中对 HTML 页面中的所有元素进行访问。

* Document 对象集合
	* all[]	提供对文档中所有 HTML 元素的访问。
	* anchors[]	返回对文档中所有 Anchor 对象的引用。
	* applets	返回对文档中所有 Applet 对象的引用。
	* forms[]	返回对文档中所有 Form 对象引用。
	* images[]	返回对文档中所有 Image 对象引用。
	* links[]	返回对文档中所有 Area 和 Link 对象引用。

* Document 对象属性
	* body	提供对 <body> 元素的直接访问。 对于定义了框架集的文档，该属性引用最外层的 <frameset>。
	* cookie	设置或返回与当前文档有关的所有 cookie。
	* domain	返回当前文档的域名。
	* lastModified	返回文档被最后修改的日期和时间。
	* referrer	返回载入当前文档的文档的 URL。
	* title	返回当前文档的标题。
	* URL	返回当前文档的 URL。
* Document 对象方法
	* close()	关闭用 document.open() 方法打开的输出流，并显示选定的数据。
	* getElementById()	返回对拥有指定 id 的第一个对象的引用。
	* getElementsByName()	返回带有指定名称的对象集合。
	* getElementsByTagName()	返回带有指定标签名的对象集合。
	* open()	打开一个流，以收集来自任何 document.write() 或 document.writeln() 方法的输出。
	* write()	向文档写 HTML 表达式 或 JavaScript 代码。
	* writeln()	等同于 write() 方法，不同的是在每个表达式之后写一个换行符。
* **在Chrome Browse中操作Document**
![](img/console.png)


# 3、使用Jsoup操作HTML文档

### 3.1、Jsoup 是什么？
jsoup 是一款Java 的HTML解析器，可直接解析某个URL地址、HTML文本内容。它提供了一套非常省力的API，可通过DOM，CSS以及类似于jQuery的操作方法来取出和操作数据。

![](img/jsoup.png)

[官网地址](https://jsoup.org/)

### 3.2、JSOUP的核心功能
* JSOUP的输入信息
	* 字符串
	* 文件
	* URL
* JSOUP抽取数据
	* 使用Document语法进行解析数据
	* 使用选择器的方式进行解析（学习对象）

### 3.3、如何使用Jsoup选择器获取数据

jsoup elements对象支持类似于CSS(或jquery)的选择器语法，来实现非常强大和灵活的查找功能。.

这个select方法在Document,Element,或Elements对象中都可以使用。且是上下文相关的，因此可实现指定元素的过滤，或者链式选择访问。

Select方法将返回一个Elements集合，并提供一组方法来抽取和处理结果。

* Selector选择器概述
	* tagname: 通过标签查找元素，比如：a
	* ns|tag: 通过标签在命名空间查找元素，比如：可以用 fb|name 语法来查找 <fb:name> 元素
	* id: 通过ID查找元素，比如：#logo
	* class: 通过class名称查找元素，比如：.masthead
	* [attribute]: 利用属性查找元素，比如：[href]
		* [^attr]: 利用属性名前缀来查找元素，比如：可以用[^data-] 来查找带有HTML5 Dataset属性的元素
		* [attr=value]: 利用属性值来查找元素，比如：[width=500]
		* [attr^=value], [attr$=value], [attr*=value]: 利用匹配属性值开头、结尾或包含属性值来查找元素，比如：[href*=/path/]
		* [attr~=regex]: 利用属性值匹配正则表达式来查找元素，比如： img[src~=(?i)\.(png|jpe?g)]
	* *: 这个符号将匹配所有元素
* Seector选择器组合使用
	* el#id: 元素+ID，比如： div#logo
	* el.class: 元素+class，比如： div.masthead
	* el[attr]: 元素+class，比如： a[href]
	* 任意组合，比如：a[href].highlight
	* ancestor child: 查找某个元素下子元素，比如：可以用.body p 查找在"body"元素下的所有 p元素
	* parent > child: 查找某个父元素下的直接子元素，比如：可以用div.content > p 查找 p 元素，也可以用body > * 查找body标签下所有直接子元素
	* siblingA + siblingB: 查找在A元素之前第一个同级元素B，比如：div.head + div
	* siblingA ~ siblingX: 查找A元素之前的同级X元素，比如：h1 ~ p
	* el, el, el:多个选择器组合，查找匹配任一选择器的唯一元素，例如：div.masthead, div.logo
* 伪选器selectors
	* :lt(n): 查找哪些元素的同级索引值（它的位置在DOM树中是相对于它的父节点）小于n，比如：td:lt(3) 表示小于三列的元素
	* :gt(n):查找哪些元素的同级索引值大于n，比如： div p:gt(2)表示哪些div中有包含2个以上的p元素
	* :eq(n): 查找哪些元素的同级索引值与n相等，比如：form input:eq(1)表示包含一个input标签的Form元素
	* :has(seletor): 查找匹配选择器包含元素的元素，比如：div:has(p)表示哪些div包含了p元素
	* :not(selector): 查找与选择器不匹配的元素，比如： div:not(.logo) 表示不包含 class=logo 元素的所有 div 列表
	* :contains(text): 查找包含给定文本的元素，搜索不区分大不写，比如： p:contains(jsoup)
	* :containsOwn(text): 查找直接包含给定文本的元素
	* :matches(regex): 查找哪些元素的文本匹配指定的正则表达式，比如：div:matches((?i)login)
	* :matchesOwn(regex): 查找自身包含文本匹配指定正则表达式的元素
	* 注意：上述伪选择器索引是从0开始的，也就是说第一个元素索引值为0，第二个元素index为1等

### 3.4、Jsoup的maven依赖

```java
<dependency>
  <!-- jsoup HTML parser library @ https://jsoup.org/ -->
  <groupId>org.jsoup</groupId>
  <artifactId>jsoup</artifactId>
  <version>1.10.3</version>
</dependency>
```

### 3.5、HTML页面解析实战
```java
package cn.itcast.sspc.base;

import java.nio.charset.Charset;

import org.apache.http.client.fluent.Request;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

/**
 * 使用Jsoup解析网页数据 
 */
public class JsoupTest {

	public static void main(String[] args) throws Exception {
		// 1、准备数据
		String html = Request.Get("http://www.itcast.cn").execute().returnContent().asString(Charset.forName("utf-8"));

		// 2、使用Jsoup获取一个docment对象
		Document doc = Jsoup.parse(html);
		// 3、解析数据
		// 3.1 获取的标题
		String title = doc.title();
		System.out.println(title);
		// 3.2 获取所有的a标签
		Elements els = doc.select("a");
		// 3.4 获取所有的class
		els = doc.select(".icon_fuli");
		
		//3.5 获取有某个属性的所有标签
		els  = doc.select("[style]");
		//3.5.1 匹配某个属性的前缀来查询
		els  = doc.select("[^s]");
		//3.5.2 判断属性值等于xxx
		els = doc.select("[href=/channel/flow.shtml]");
		
		//4、组合选择器
		els = doc.select("div.fast_path");
		//5、找某个模块下的a标签
		els = doc.select("div.fast_path a");
		for(Element el : els){
			System.out.println(el);
		}

	}

}
```